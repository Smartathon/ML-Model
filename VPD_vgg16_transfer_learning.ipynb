{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jF09LPGwcoU4"
      },
      "outputs": [],
      "source": [
        "#This code is submitted for smartathon for Visual pollution detection using VGG-16 model with transfer learning approach"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Sxeb3HYBfkeo",
        "outputId": "1ebef161-c432-487d-a08f-e86b99910cef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBS7j7RGhrLk"
      },
      "outputs": [],
      "source": [
        "#import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing import image\n",
        "from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the annotations from the CSV file\n",
        "annotations = pd.read_csv(\"/content/drive/MyDrive/dataset/sample_train.csv\")\n",
        "\n",
        "# Extract the classes and file paths from the annotations\n",
        "classes = annotations[\"name\"].values\n",
        "file_paths = annotations[\"image_path\"].values\n",
        "\n",
        "# Extract the bounding boxes from the annotations\n",
        "bounding_boxes = annotations[[\"xmin\", \"ymin\", \"xmax\", \"ymax\"]].values\n"
      ],
      "metadata": {
        "id": "W8ZqXGA1hxDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the images and their corresponding classes and bounding boxes\n",
        "X = []\n",
        "y = []\n",
        "bboxes = []\n",
        "for file_path, class_name, bbox in zip(file_paths, classes, bounding_boxes):\n",
        "    img = Image.open(\"/content/drive/MyDrive/dataset/sample_images/\" + file_path)\n",
        "    img = img.resize((960, 960))\n",
        "    X.append(np.array(img))\n",
        "    y.append(class_name)\n",
        "    bboxes.append(bbox)\n",
        "\n",
        "# Convert the classes and bounding boxes to numpy arrays\n",
        "num_classes = len(np.unique(y))\n",
        "encoder = LabelEncoder()\n",
        "y = encoder.fit_transform(y)\n",
        "y = to_categorical(y, num_classes)\n",
        "bboxes = np.array(bboxes)\n",
        "print(num_classes)\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val, bboxes_train, bboxes_val = train_test_split(X, y, bboxes, test_size=1)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76eel5wuhxPG",
        "outputId": "aade9fa3-4383-4e16-a521-3032259e07a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the VGG16 model with pre-trained weights\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(960, 960, 3))"
      ],
      "metadata": {
        "id": "2Gz5kHXThxUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a new fully connected layer for the 11 classes\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "predictions = Dense(11, activation='softmax')(x)\n"
      ],
      "metadata": {
        "id": "RHomgJzVhxZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new model with the new fully connected layer\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the layers of the base model\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n"
      ],
      "metadata": {
        "id": "531jb3lzhxf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the new model\n",
        "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "G6gjmGaOkDC0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0639e14-db20-49c2-be63-89e10237a86b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#labelling as binary\n",
        "label_as_binary = LabelBinarizer()\n",
        "train_y = label_as_binary.fit_transform(y_train)\n",
        "print(np.unique(y_train))\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "bZ_clkzUQtgt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac777f77-6775-42d7-ccac-f76536de6725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 1.]\n",
            "(202, 11)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(np.array(X_train),y_train, batch_size=5, epochs=10, validation_data=(np.array(X_val), np.array(y_val)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmvPdZvlkFyO",
        "outputId": "355586b4-2253-455e-b825-8c9bddc0108f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "41/41 [==============================] - 56s 965ms/step - loss: 628.5138 - accuracy: 0.4356 - val_loss: 1972.6261 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "41/41 [==============================] - 30s 726ms/step - loss: 388.2005 - accuracy: 0.7822 - val_loss: 1225.9535 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "41/41 [==============================] - 30s 724ms/step - loss: 258.5515 - accuracy: 0.8267 - val_loss: 2230.8132 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "41/41 [==============================] - 30s 736ms/step - loss: 290.8881 - accuracy: 0.8218 - val_loss: 1807.8984 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "41/41 [==============================] - 30s 728ms/step - loss: 277.1537 - accuracy: 0.8515 - val_loss: 1771.5693 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "41/41 [==============================] - 30s 727ms/step - loss: 384.4093 - accuracy: 0.8069 - val_loss: 1918.4377 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "41/41 [==============================] - 30s 731ms/step - loss: 324.2781 - accuracy: 0.8267 - val_loss: 1777.3337 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "41/41 [==============================] - 30s 730ms/step - loss: 385.9737 - accuracy: 0.8218 - val_loss: 1206.3586 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "41/41 [==============================] - 30s 733ms/step - loss: 383.1049 - accuracy: 0.8069 - val_loss: 1159.9158 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "41/41 [==============================] - 30s 731ms/step - loss: 290.1411 - accuracy: 0.8119 - val_loss: 1271.4458 - val_accuracy: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4493d7c4f0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model\n",
        "model.save(\"vgg16_transfer_learning_model_1.h5\")"
      ],
      "metadata": {
        "id": "l2xd7JJvkKa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model prediction\n",
        "\n",
        "# Extract the file paths from the annotations\n",
        "\n",
        "annots = pd.read_csv(\"/content/drive/MyDrive/dataset/sample_train.csv\"\n",
        "\n",
        "file_paths = annots[\"image_path\"].values\n",
        "\n",
        "#for storing in CSV file\n",
        "results = pd.DataFrame(columns=[\"class\",\"image_path\",\"name\",\"xmax\",\"xmin\",\"ymax\",\"ymin\"])\n",
        "\n",
        "# Load the test image\n",
        "\n",
        "for file_path in file_paths:\n",
        "    img = Image.open(\"/content/drive/MyDrive/dataset/sample_images/\" + file_path)\n",
        "    img = img.resize((960, 960))\n",
        "    x = np.asarray(img)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    x = preprocess_input(x)\n",
        "    # Make predictions\n",
        "    preds = model.predict(x)\n",
        "    # Get the class with the highest probability\n",
        "    predicted_class = np.argmax(preds)\n",
        "    # Get the class label\n",
        "    class_label = classes[predicted_class]\n",
        "    #bounding box metrics\n",
        "    bbox = bounding_boxes[predicted_class]\n",
        "    # Get the bounding box coordinates\n",
        "    xmin, ymin, xmax, ymax = bbox\n",
        "\n",
        "    \n",
        "    # Append the results to the dataframe\n",
        "    results = results.append({\"class\": predicted_class,\"image_path\":file_path, \"name\": class_label, \"xmax\": xmax,\"xmin\": xmin,\"ymax\": ymax,\"ymin\": ymin}, ignore_index=True)\n",
        "    results.to_csv(\"/content/drive/MyDrive/dataset/result.csv\", index=False)\n",
        "\n",
        "    \n",
        "\n"
      ],
      "metadata": {
        "id": "-lFrRQvp0lae"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}